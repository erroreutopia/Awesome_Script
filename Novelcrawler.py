#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°è¯´çˆ¬è™«ï¼šè¾“å…¥ç›®å½•é¡µ â†’ ä¸‹è½½ç« èŠ‚ â†’ ç”Ÿæˆå¸¦å°é¢çš„ EPUB
æ”¯æŒè‡ªå®šä¹‰æ ‡é¢˜ã€ä½œè€…ã€å°é¢ï¼ˆæœ¬åœ°æˆ–ç½‘ç»œï¼‰
é€‚é… Chromium + chromedriverï¼ˆå·²åœ¨ PATH ä¸­ï¼‰
"""

import os
import re
import time
import traceback
import requests
from urllib.parse import urlparse
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from bs4 import BeautifulSoup
from ebooklib import epub

# === é…ç½® ===
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
NOVEL_DIR = os.path.join(SCRIPT_DIR, "novel")
os.makedirs(NOVEL_DIR, exist_ok=True)

# Chromium è·¯å¾„ï¼ˆLinux å¸¸è§è·¯å¾„ï¼Œå¯æŒ‰éœ€ä¿®æ”¹ï¼‰
CHROMIUM_PATH = "/usr/bin/chromium"

chrome_options = Options()
chrome_options.binary_location = CHROMIUM_PATH
chrome_options.add_argument("--headless")
chrome_options.add_argument("--no-sandbox")
chrome_options.add_argument("--disable-dev-shm-usage")
chrome_options.add_argument("--disable-gpu")
chrome_options.add_argument("--disable-images")
chrome_options.add_argument("--log-level=3")

print("æ­£åœ¨å¯åŠ¨æµè§ˆå™¨...")
driver = webdriver.Chrome(options=chrome_options)

def sanitize_filename(name):
    return re.sub(r'[\\/:*?"<>|]', '_', name).strip() or "novel"

def extract_chapter_links(toc_url):
    print("æ­£åœ¨åŠ è½½ç›®å½•é¡µ...")
    driver.get(toc_url)
    time.sleep(2)
    soup = BeautifulSoup(driver.page_source, 'lxml')

    links = []
    for a in soup.find_all('a', href=True):
        text = a.get_text(strip=True)
        if re.search(r'ç¬¬[é›¶ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾\d]+ç« ', text):
            href = a['href']
            if href.startswith('/'):
                from urllib.parse import urljoin
                href = urljoin(toc_url, href)
            elif not href.startswith(('http://', 'https://')):
                href = toc_url.rstrip('/') + '/' + href.lstrip('/')
            links.append((text, href))
    return links

def get_chapter_content(ch_url):
    driver.get(ch_url)
    time.sleep(1.2)
    page_source = driver.page_source
    soup = BeautifulSoup(page_source, 'lxml')

    # ä¿å­˜åŸå§‹é¡µé¢ç”¨äºè°ƒè¯•
    debug_dir = os.path.join(NOVEL_DIR, "debug_pages")
    os.makedirs(debug_dir, exist_ok=True)
    safe_name = re.sub(r'[\\/:*?"<>|]', '_', ch_url.replace('https://', '').replace('http://', ''))[:100]
    with open(os.path.join(debug_dir, f"{safe_name}.html"), "w", encoding="utf-8") as f:
        f.write(page_source)

    # ç­–ç•¥1ï¼šå¸¸è§æ­£æ–‡å®¹å™¨
    selectors = [
        '#content', '.content', '#chapter-content', '.chapter-content',
        '.read-content', '#read-content', '.txt', '.text', '.article-content',
        'article', 'main', '.post-content', '.entry-content', '.bookcontent'
    ]
    for sel in selectors:
        elem = soup.select_one(sel)
        if elem:
            print(f"  âœ… ä½¿ç”¨é€‰æ‹©å™¨ '{sel}' æå–æˆåŠŸ")
            return str(elem)

    # ç­–ç•¥2ï¼šä»â€œç¬¬Xç« â€æ ‡é¢˜å¾€åæ‰¾å…„å¼ŸèŠ‚ç‚¹
    for elem in soup.find_all(string=re.compile(r'ç¬¬[é›¶ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾\d]+ç« ')):
        title_elem = elem.parent
        if title_elem and title_elem.parent:
            parts = []
            for sibling in title_elem.parent.next_siblings:
                if hasattr(sibling, 'name') and sibling.name in ['p', 'div']:
                    txt = sibling.get_text(strip=True)
                    if len(txt) > 10:
                        parts.append(str(sibling))
            if parts:
                print("  âœ… é€šè¿‡æ ‡é¢˜åå…„å¼ŸèŠ‚ç‚¹æå–æˆåŠŸ")
                return ''.join(parts)

    # ç­–ç•¥3ï¼šé€€åŒ–åˆ°æ‰€æœ‰é•¿æ®µè½
    paragraphs = soup.find_all('p')
    long_ps = [str(p) for p in paragraphs if len(p.get_text(strip=True)) > 20]
    if len(long_ps) > 2:
        print("  âš ï¸ é€€åŒ–ï¼šä½¿ç”¨ <p> æ ‡ç­¾ç»„åˆ")
        return ''.join(long_ps)

    print("  âŒ æ­£æ–‡æå–å¤±è´¥ï¼åŸå§‹é¡µé¢å·²ä¿å­˜åˆ° debug_pages/")
    return "<p>æ­£æ–‡æå–å¤±è´¥ï¼Œè¯·æŸ¥çœ‹ debug_pages/ ä¸­çš„ HTML æ–‡ä»¶ã€‚</p>"

def create_epub(title, author, cover_path_or_url, chapters, output_dir):
    safe_title = sanitize_filename(title or "å°è¯´")
    book = epub.EpubBook()
    book.set_identifier(f'novel_{abs(hash(safe_title)) % (10**8)}')
    book.set_title(title or "å°è¯´")
    book.set_language('zh')
    book.add_author(author or "åŒ¿å")

    # å¤„ç†å°é¢
    if cover_path_or_url:
        try:
            if cover_path_or_url.startswith(('http://', 'https://')):
                print("æ­£åœ¨ä¸‹è½½å°é¢...")
                resp = requests.get(cover_path_or_url, timeout=10)
                resp.raise_for_status()
                cover_data = resp.content
                content_type = resp.headers.get('content-type', 'image/jpeg')
                if 'png' in content_type:
                    cover_ext = "png"
                elif 'gif' in content_type:
                    cover_ext = "gif"
                else:
                    cover_ext = "jpg"
            else:
                if not os.path.exists(cover_path_or_url):
                    print(f"âš ï¸ å°é¢æ–‡ä»¶ä¸å­˜åœ¨: {cover_path_or_url}ï¼Œè·³è¿‡å°é¢")
                    cover_data = None
                else:
                    with open(cover_path_or_url, "rb") as f:
                        cover_data = f.read()
                    _, ext = os.path.splitext(cover_path_or_url)
                    cover_ext = ext.lower().lstrip('.')

            if cover_data:
                cover_file_name = f"cover.{cover_ext}"
                book.set_cover(cover_file_name, cover_data)

        except Exception as e:
            print(f"âš ï¸ å°é¢åŠ è½½å¤±è´¥: {e}")

    # æ·»åŠ ç« èŠ‚
    spine = ['nav']
    toc = []
    for i, (ch_title, ch_html) in enumerate(chapters):
        chapter = epub.EpubHtml(
            title=ch_title,
            file_name=f'chap_{i+1:04}.xhtml',
            lang='zh'
        )
        chapter.content = f'<h1>{ch_title}</h1>' + (ch_html or "<p>ç©ºå†…å®¹</p>")
        book.add_item(chapter)
        toc.append(chapter)
        spine.append(chapter)

    book.toc = tuple(toc)
    book.add_item(epub.EpubNcx())
    book.add_item(epub.EpubNav())
    book.spine = spine

    epub_path = os.path.join(output_dir, f"{safe_title}.epub")
    epub.write_epub(epub_path, book)
    return epub_path

# === ä¸»ç¨‹åº ===
if __name__ == '__main__':
    try:
        TOC_URL = input("è¯·è¾“å…¥å°è¯´ç›®å½•é¡µå®Œæ•´é“¾æ¥ï¼ˆä»¥ http:// æˆ– https:// å¼€å¤´ï¼‰: ").strip()
        if not TOC_URL.startswith(('http://', 'https://')):
            print("âŒ é“¾æ¥æ ¼å¼é”™è¯¯ï¼")
            exit(1)

        chapter_list = extract_chapter_links(TOC_URL)
        print(f"âœ… å…±è¯†åˆ«åˆ° {len(chapter_list)} ç« ")

        if not chapter_list:
            print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•ç« èŠ‚ï¼Œè¯·ç¡®è®¤é¡µé¢åŒ…å«â€œç¬¬Xç« â€å­—æ ·ã€‚")
            exit(1)

        # è·å–é»˜è®¤ä¹¦å
        driver.get(TOC_URL)
        time.sleep(1)
        try:
            default_title = driver.title.replace('ç›®å½•', '').replace('å°è¯´', '').replace('æœ€æ–°ç« èŠ‚', '').strip()
        except:
            default_title = "æˆ‘çš„å°è¯´"

        # ç”¨æˆ·è‡ªå®šä¹‰å…ƒæ•°æ®
        print("\n--- EPUB å…ƒæ•°æ®è®¾ç½®ï¼ˆç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤å€¼ï¼‰ ---")
        custom_title = input(f"ä¹¦åï¼ˆé»˜è®¤: {default_title}ï¼‰: ").strip() or default_title
        custom_author = input("ä½œè€…ï¼ˆé»˜è®¤: åŒ¿åï¼‰: ").strip() or "åŒ¿å"
        cover_input = input("å°é¢ï¼ˆæœ¬åœ°è·¯å¾„å¦‚ cover.jpgï¼Œæˆ–ç½‘ç»œé“¾æ¥ï¼Œç•™ç©ºåˆ™æ— å°é¢ï¼‰: ").strip()

        # ä¸‹è½½ç« èŠ‚
        chapters_content = []
        for i, (ch_title, ch_url) in enumerate(chapter_list):
            print(f"[{i+1}/{len(chapter_list)}] æ­£åœ¨ä¸‹è½½ï¼š{ch_title}")
            try:
                content = get_chapter_content(ch_url)
                chapters_content.append((ch_title, content))
                print(f"    â†’ æå–åˆ° {len(content)} å­—ç¬¦")
            except Exception as e:
                print(f"    âŒ é”™è¯¯: {e}")
                traceback.print_exc()
                chapters_content.append((ch_title, "<p>åŠ è½½å¼‚å¸¸</p>"))

        # ç”Ÿæˆ EPUB
        print("æ­£åœ¨ç”Ÿæˆ EPUB...")
        epub_file = create_epub(
            title=custom_title,
            author=custom_author,
            cover_path_or_url=cover_input,
            chapters=chapters_content,
            output_dir=NOVEL_DIR
        )
        print(f"ğŸ‰ å®Œæˆï¼EPUB å·²ä¿å­˜è‡³ï¼š{epub_file}")
        print(f"ğŸ“„ è°ƒè¯• HTML åœ¨ï¼š{os.path.join(NOVEL_DIR, 'debug_pages')}")

    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­ã€‚")
    except Exception as e:
        print(f"âŒ ç¨‹åºå´©æºƒ: {e}")
        traceback.print_exc()
    finally:
        print("æ­£åœ¨å…³é—­æµè§ˆå™¨...")
        driver.quit()